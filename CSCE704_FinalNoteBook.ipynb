{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCE704_FinalNoteBook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishruthRG/MetaLearning_CSCE704_Project/blob/main/CSCE704_FinalNoteBook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Learning to choose between classifiers for fake news detection"
      ],
      "metadata": {
        "id": "LX6e6o1LQQhL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC4cM4T22UkZ",
        "outputId": "3a25fbd0-46ea-45c7-f618-b9d83bc2e248"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "JrtGh9vPDGwS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb9-ON7c004P"
      },
      "source": [
        "# Importing libraries to measure performace\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Used to vectorize news text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing SVC model\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Importing RFC model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import random\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting and storing data by combining data from 2 datasets"
      ],
      "metadata": {
        "id": "uU7d1snBEPYJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlWUi6ef1Nl4"
      },
      "source": [
        "# DATASET 1\n",
        "real_fake_file_name=\"/content/drive/Shareddrives/CSCE_704_Project/fake_or_real_news.csv\"\n",
        "\n",
        "# DATASET 2\n",
        "fake_file_name=\"/content/drive/Shareddrives/CSCE_704_Project/Fake.csv\"\n",
        "real_file_name=\"/content/drive/Shareddrives/CSCE_704_Project/True.csv\"\n",
        "\n",
        "# Combined data set\n",
        "dataset=[]\n",
        "\n",
        "titles=[] # Holds news article titles\n",
        "text=[] # Holds news article texts\n",
        "labels=[] # Holds news article label (real/fake)\n",
        "\n",
        "with open(real_fake_file_name) as file:\n",
        "  csvreader = csv.reader(file)\n",
        "  header = next(csvreader)\n",
        "  rows = []\n",
        "  for row in csvreader:\n",
        "    titles.append(row[1]) #title\n",
        "    text.append(row[2]) #text\n",
        "    labels.append(row[3]) #label\n",
        "\n",
        "with open(fake_file_name) as file:\n",
        "  csvreader = csv.reader(file)\n",
        "  header = next(csvreader)\n",
        "  rows = []\n",
        "  for row in csvreader:\n",
        "    titles.append(row[0]) #title\n",
        "    text.append(row[1]) #text\n",
        "    labels.append(\"FAKE\") #label\n",
        "\n",
        "with open(real_file_name) as file:\n",
        "  csvreader = csv.reader(file)\n",
        "  header = next(csvreader)\n",
        "  rows = []\n",
        "  for row in csvreader:\n",
        "    titles.append(row[0]) #title\n",
        "    text.append(row[1]) #text\n",
        "    labels.append(\"REAL\") #label\n",
        "\n",
        "dataset.append(titles)\n",
        "dataset.append(text)\n",
        "dataset.append(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorizing the data and making a train test split"
      ],
      "metadata": {
        "id": "9aVeGN48FUHu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVd7ITLX1OWy"
      },
      "source": [
        "# Vectorize all news texts\n",
        "all_text_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "all_text_vectorized = all_text_vectorizer.fit_transform(dataset[1]) # vectorizing news text\n",
        "\n",
        "# 40% train, 60% test split\n",
        "master_data_train, master_data_test, master_labels_train, master_labels_test = train_test_split(all_text_vectorized, dataset[2], test_size=0.6, random_state = 30)\n",
        "\n",
        "# Further splitting the 60% into 25000(MLP training) + 5740 (Final/MLP testing)\n",
        "nn_data_train = master_data_test[:25000] # 25000 MLP training data points\n",
        "nn_data_test = master_data_test[25000:] # 5740 MLP testing data points\n",
        "\n",
        "final_labels_train_tf =  master_labels_test[:25000] # 25000 lables used for MLP training\n",
        "final_labels_test_tf =  master_labels_test[25000:] # last 5740 labels kept seperate for Final/MLP testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting a Support Vector Classifer (SVC)"
      ],
      "metadata": {
        "id": "cTMO3bzOGpB-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt7-Lv3d1Rmf",
        "outputId": "69adf80d-8668-4007-c93f-df5337eaca66"
      },
      "source": [
        "model_svc = SVC(kernel='linear') # linear kernel becuase it gave the best results\n",
        "model_svc.fit(master_data_train, master_labels_train) # fit the SVC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the SVC"
      ],
      "metadata": {
        "id": "PRMQmsNiHSLS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBJhUWe51XNF"
      },
      "source": [
        "pred_svc = model_svc.predict(master_data_test) # 30740 predictions\n",
        "pred_svc_final = pred_svc[25000:] # last 5740 kept aside for final evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC classification report"
      ],
      "metadata": {
        "id": "VccI4hAzHjdL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj7dCi3l1cjI",
        "outputId": "590863ed-3d9c-43aa-8e83-10dd43f7527c"
      },
      "source": [
        "print(\"SVC classification report:\")\n",
        "print(classification_report(final_labels_test_tf, pred_svc_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.95      0.97      0.96      2939\n",
            "        REAL       0.97      0.95      0.96      2801\n",
            "\n",
            "    accuracy                           0.96      5740\n",
            "   macro avg       0.96      0.96      0.96      5740\n",
            "weighted avg       0.96      0.96      0.96      5740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting a Random Forest Classifer (RFC)"
      ],
      "metadata": {
        "id": "5qEfE8GNIliX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVLxrAKI1fId",
        "outputId": "b9a2e7a7-5590-4c45-bbbc-db810bb832c8"
      },
      "source": [
        "model_rfc = RandomForestClassifier(n_estimators=200, max_depth=500) # optimal hyperparameters for random forest classifier for this dataset\n",
        "model_rfc.fit(master_data_train, master_labels_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=500, n_estimators=200)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the RFC"
      ],
      "metadata": {
        "id": "A5YSKQdtIrYc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLfc82x91hmJ"
      },
      "source": [
        "pred_rfc = model_rfc.predict(master_data_test) # 30740 predictions\n",
        "pred_rfc_final = pred_rfc[25000:] # last 5740 kept aside for final evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RFC classification report"
      ],
      "metadata": {
        "id": "G6CP68LNIy1C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSwNzPvg1j_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95ece95-d985-43dc-d74b-62559ae39eb4"
      },
      "source": [
        "print(\"RFC classification report:\")\n",
        "print(classification_report(final_labels_test_tf, pred_rfc_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RFC classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.94      0.96      0.95      2939\n",
            "        REAL       0.96      0.93      0.95      2801\n",
            "\n",
            "    accuracy                           0.95      5740\n",
            "   macro avg       0.95      0.95      0.95      5740\n",
            "weighted avg       0.95      0.95      0.95      5740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a training set for the Multilayer Perceptron Classifier (MLP)"
      ],
      "metadata": {
        "id": "I_uqbUV2IUHH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG204q181mP_"
      },
      "source": [
        "nn_labels_train = []\n",
        "\n",
        "# RFC is fed in as 0 and SVC as 1\n",
        "for rfc_pred,svc_pred, true_label in zip(pred_rfc[0:25000],pred_svc[0:25000], final_labels_train_tf):\n",
        "  if rfc_pred == true_label and svc_pred == true_label: #if RFC and SVC are both correct randomly feed in RFC or SVC to the MLP\n",
        "    b = random.randint(0, 1)\n",
        "    nn_labels_train.append(b)\n",
        "  elif rfc_pred == true_label and svc_pred != true_label: #if only RFC is correct feed in RFC to the MLP\n",
        "    nn_labels_train.append(0)\n",
        "  elif rfc_pred != true_label and svc_pred == true_label: #if only SVC is correct feed in SVC to the MLP\n",
        "    nn_labels_train.append(1)\n",
        "  else: #if RFC and SVC are both wrong randomly feed in RFC or SVC to the MLP\n",
        "    b = random.randint(0, 1)\n",
        "    nn_labels_train.append(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the MLP"
      ],
      "metadata": {
        "id": "jxbyVrGWJIxi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_JSa6sI1vBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb29739-9e13-438b-9474-703c203ba314"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "model_nn1 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 25, 25), random_state=1, max_iter=1000)\n",
        "model_nn1.fit(nn_data_train, nn_labels_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(100, 25, 25), max_iter=1000,\n",
              "              random_state=1, solver='lbfgs')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the MLP"
      ],
      "metadata": {
        "id": "yWIlwxcZJDTm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvc2SuWu1w3c"
      },
      "source": [
        "nn_preds = model_nn1.predict(nn_data_test) # Holds RFC/SVC in binary format (0 -> RFC; 1-> SVC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting final true/false predictions from the MLP"
      ],
      "metadata": {
        "id": "dQNq2en5J2j6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBKm1abE12Ow"
      },
      "source": [
        "final_preds= [] # Holds REAL/FAKE translated from RFC/SVC\n",
        "#for each final test data point see which classifier the MLP predicted and record the real/fake prediction that classifer made\n",
        "for each_nn_prediction, final_test_data in zip(nn_preds,nn_data_test):\n",
        "  if each_nn_prediction == 0:\n",
        "    pred = model_rfc.predict(final_test_data)\n",
        "    final_preds.append(pred)\n",
        "  else:\n",
        "    pred = model_svc.predict(final_test_data)\n",
        "    final_preds.append(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP classification report"
      ],
      "metadata": {
        "id": "bww-OnyZKafw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13qpItps14E7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43af127-5e11-4852-e0c2-38a948ccf9db"
      },
      "source": [
        "print(\"MLP classification report:\")\n",
        "print(classification_report(final_labels_test_tf,final_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.95      0.97      0.96      2939\n",
            "        REAL       0.97      0.94      0.96      2801\n",
            "\n",
            "    accuracy                           0.96      5740\n",
            "   macro avg       0.96      0.96      0.96      5740\n",
            "weighted avg       0.96      0.96      0.96      5740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate final performance"
      ],
      "metadata": {
        "id": "6I_dxHZzKjOQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwRTaDgtmXcY",
        "outputId": "7a935f0c-8859-47e0-f836-5c8b6ed8d957"
      },
      "source": [
        "nn_predicts_rfc = 0\n",
        "nn_predicts_svc = 0\n",
        "\n",
        "svc_correct_when_svc=0\n",
        "svc_wrong_when_svc=0\n",
        "rfc_correct_when_svc=0\n",
        "rfc_wrong_when_svc=0\n",
        "\n",
        "svc_correct_when_rfc=0\n",
        "svc_wrong_when_rfc=0\n",
        "rfc_correct_when_rfc=0\n",
        "rfc_wrong_when_rfc=0\n",
        "\n",
        "for each_nn_pred, i in zip(nn_preds, range(len(final_labels_test_tf))):\n",
        "  if each_nn_pred == 0: ## MLP predicted RFC\n",
        "    nn_predicts_rfc += 1\n",
        "    if pred_rfc_final[i] == final_labels_test_tf[i]:\n",
        "      rfc_correct_when_rfc += 1\n",
        "    else:\n",
        "      rfc_wrong_when_rfc +=1\n",
        "    \n",
        "    if pred_svc_final[i] == final_labels_test_tf[i]:\n",
        "      svc_correct_when_rfc+=1\n",
        "    else:\n",
        "      svc_wrong_when_rfc +=1\n",
        "\n",
        "  else: # MLP predicted SVC\n",
        "    nn_predicts_svc += 1\n",
        "    if pred_svc_final[i] == final_labels_test_tf[i]:\n",
        "      svc_correct_when_svc+=1\n",
        "    else:\n",
        "      svc_wrong_when_svc +=1\n",
        "\n",
        "    if pred_rfc_final[i] == final_labels_test_tf[i]:\n",
        "      rfc_correct_when_svc += 1\n",
        "    else:\n",
        "      rfc_wrong_when_svc +=1\n",
        "\n",
        "# Printing final results of neural network\n",
        "\n",
        "print(\"Neural network picked SVC:\", nn_predicts_svc, \"times\")\n",
        "print(\"In these\",nn_predicts_svc,\"times that the neural netowork chose to use SVC:\")\n",
        "print(\"SVC was correct\", svc_correct_when_svc, \"times\")\n",
        "print(\"SVC was wrong\", svc_wrong_when_svc, \"times\")\n",
        "print(\"RFC was correct\", rfc_correct_when_svc, \"times\")\n",
        "print(\"RFC was wrong\", rfc_wrong_when_svc, \"times\")\n",
        "print()\n",
        "print(\"Neural network picked RFC:\", nn_predicts_rfc, \"times\")\n",
        "print(\"In these\",nn_predicts_rfc,\"times that the neural netowork chose to use RFC:\")\n",
        "print(\"RFC was correct\", rfc_correct_when_rfc, \"times\")\n",
        "print(\"RFC was wrong\", rfc_wrong_when_rfc, \"times\")\n",
        "print(\"SVC was correct\", svc_correct_when_rfc, \"times\")\n",
        "print(\"SVC was wrong\", svc_wrong_when_rfc, \"times\")\n",
        "print()\n",
        "\n",
        "disagree = 0\n",
        "correct_picks_by_nn = 0\n",
        "wrong_picks_by_nn = 0\n",
        "\n",
        "for i in range(5740):\n",
        "  if pred_rfc_final[i] != pred_svc_final[i]:\n",
        "    disagree += 1\n",
        "    nnPick = nn_preds[i]\n",
        "    if nnPick == 0 and pred_rfc_final[i] == final_labels_test_tf[i]:\n",
        "      correct_picks_by_nn += 1\n",
        "    elif nnPick == 1 and pred_svc_final[i] == final_labels_test_tf[i]:\n",
        "      correct_picks_by_nn += 1\n",
        "    else:\n",
        "      wrong_picks_by_nn += 1\n",
        "\n",
        "print(\"RFC and SVC disagreed on classification \", disagree, \" times\")\n",
        "print(\"Neural Network picked the correct classifier \", correct_picks_by_nn, \" times in case of disagreement\")\n",
        "print(\"Neural Network picked the wrong classifier \", wrong_picks_by_nn, \" times in case of disagreement\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network picked SVC: 2933 times\n",
            "In these 2933 times that the neural netowork chose to use SVC:\n",
            "SVC was correct 2810 times\n",
            "SVC was wrong 123 times\n",
            "RFC was correct 2749 times\n",
            "RFC was wrong 184 times\n",
            "\n",
            "Neural network picked RFC: 2807 times\n",
            "In these 2807 times that the neural netowork chose to use RFC:\n",
            "RFC was correct 2692 times\n",
            "RFC was wrong 115 times\n",
            "SVC was correct 2703 times\n",
            "SVC was wrong 104 times\n",
            "\n",
            "RFC and SVC disagreed on classification  226  times\n",
            "Neural Network picked the correct classifier  138  times in case of disagreement\n",
            "Neural Network picked the wrong classifier  88  times in case of disagreement\n"
          ]
        }
      ]
    }
  ]
}